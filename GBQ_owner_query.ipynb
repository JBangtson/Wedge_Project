{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wedge Project - Task Two\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import GoogleAPIError\n",
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "client = bigquery.Client(project=\"wedge-project-jbangtson\")\n",
    "data_directory = \"E:\\\\College\\\\Fall 2024\\\\ADA\\\\Wedge\\\\Wedge_Project\\\\data\\\\unzipped\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\380248305.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\380248305.py:1: DtypeWarning: Columns (33,34,40,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above to view all transactions for card owners: \n",
    "\n",
    "48289, 48420, 56191, 20300, 48996, 56191, and 16551.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of columns\n",
    "columns = ['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id']\n",
    "\n",
    "# Create an empty Polars DataFrame with the specified columns\n",
    "gbq_query_df = pl.DataFrame({col: [] for col in columns})\n",
    "\n",
    "print(gbq_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a query\n",
    "def run_query(query):\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "\n",
    "        bytes_processed = query_job.total_bytes_processed\n",
    "        mb_processed = bytes_processed / (1024 ** 2)\n",
    "        cost_per_tb = 5.0\n",
    "\n",
    "\n",
    "        tb_processed = bytes_processed / (1024 ** 4)  # Convert bytes to terabytes\n",
    "        estimated_cost = tb_processed * cost_per_tb\n",
    "\n",
    "        # Display the processed data and estimated cost\n",
    "        print(f\"Data processed: {mb_processed:.2f} MB\")\n",
    "        \n",
    "\n",
    "        print(f\"Estimated bytes processed: {bytes_processed}\")\n",
    "        print(f\"Estimated cost: ${estimated_cost:.10f}\\n\\n\")\n",
    "\n",
    "        print(f\"Estimated bytes processed against a full year of data: {bytes_processed*50}\")\n",
    "        print(f\"Estimated cost against a full year of data: ${estimated_cost*50:.20f}\")\n",
    "        print(f\"Estimated cost against a full year of data every 6 hours: ${(estimated_cost*50)*(4*365):.20f}\\n\\n---------------\")\n",
    "\n",
    "        \n",
    "\n",
    "        return results\n",
    "    except GoogleAPIError as e:\n",
    "        print(f\"Error running query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This next function is a modified version of the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a query\n",
    "def run_query2(query):\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        df = query_job.to_dataframe()\n",
    "        #results = query_job.result()\n",
    "\n",
    "        bytes_processed = query_job.total_bytes_processed\n",
    "        mb_processed = bytes_processed / (1024 ** 2)\n",
    "        cost_per_tb = 5.0\n",
    "\n",
    "\n",
    "        tb_processed = bytes_processed / (1024 ** 4)  # Convert bytes to terabytes\n",
    "        estimated_cost = tb_processed * cost_per_tb\n",
    "\n",
    "        # Display the processed data and estimated cost\n",
    "        print(f\"Data processed: {mb_processed:.2f} MB\")\n",
    "        \n",
    "\n",
    "        print(f\"Estimated bytes processed: {bytes_processed}\")\n",
    "        print(f\"Estimated cost: ${estimated_cost:.10f}\\n\\n\")\n",
    "\n",
    "        print(f\"Estimated bytes processed against a full year of data: {bytes_processed*50}\")\n",
    "        print(f\"Estimated cost against a full year of data: ${estimated_cost*50:.20f}\")\n",
    "        print(f\"Estimated cost against a full year of data every 6 hours: ${(estimated_cost*50)*(4*365):.20f}\\n\\n---------------\")\n",
    "\n",
    "        \n",
    "\n",
    "        return df.astype(str)\n",
    "    except GoogleAPIError as e:\n",
    "        print(f\"Error running query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_card_nums = []\n",
    "\n",
    "# distinct_card_nums = \"\"\"\n",
    "# SELECT\n",
    "#   DISTINCT(card_no) as card_no\n",
    "# FROM\n",
    "#   `the_wedge_dataset.transArchive_*`\n",
    "# WHERE card_no != 3\n",
    "# \"\"\"\n",
    "\n",
    "# # Run the query and display results\n",
    "# results = run_query(distinct_card_nums)\n",
    "# if results:\n",
    "#     for row in results:\n",
    "#         print(f\"{row.card_no}\")\n",
    "#         all_card_nums.append(row.card_no)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select 20 random numbers from the all_card_nums list\n",
    "random_card_nums = random.sample(all_card_nums, 20)\n",
    "print(random_card_nums)\n",
    "\n",
    "# Write the random_card_nums list to a tab-delimited text file\n",
    "with open('random_card_nums.txt', 'w') as f:\n",
    "    for num in random_card_nums:\n",
    "        f.write(f\"{num}\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBQ Owner Queries\n",
    "\n",
    "This code defines a function save_owner_query_to_file() that retrieves and saves data from a Google BigQuery dataset to a CSV file. \n",
    "\n",
    "The function takes two arguments: yearOfQuery (the year to filter the data by) and table-by-table \n",
    "(a boolean flag that controls whether to process each table individually or as a group). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\4247815683.py:30: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{yearOfQuery}.txt', sep='\\t', index=False)\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\4247815683.py:60: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{file.split('.')[0]}_version2.txt', sep='\\t', index=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def save_owner_query_to_file(yearOfQuery, tableByTable=False):\n",
    "    \n",
    "  if tableByTable:\n",
    "\n",
    "    for idx, file in enumerate(os.listdir(data_directory)):\n",
    "      owner_query_df = pd.DataFrame()\n",
    "      if f\"transArchive_{yearOfQuery}\" in file:\n",
    "      \n",
    "\n",
    "        owner_gbq_query = f\"\"\"\n",
    "        SELECT\n",
    "          *,\n",
    "        SAFE_CAST(Scale AS INT64) AS IntScale\n",
    "        FROM\n",
    "          `the_wedge_dataset.transArchive_{yearOfQuery}*`\n",
    "        WHERE card_no = 48289.0 OR card_no = 48420.0 OR card_no = 56191.0 OR card_no = 20300.0 OR card_no = 48996.0 OR card_no = 56191.0 OR card_no = 16551.0 \n",
    "        \"\"\"\n",
    "\n",
    "        temp_df = run_query2(owner_gbq_query)\n",
    "\n",
    "        # #temp_df = pl.DataFrame(results)\n",
    "\n",
    "        # rows = [dict(row) for row in results]\n",
    "        # #columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "        # # Create Polars DataFrame from the rows\n",
    "        # temp_df = pl.DataFrame(rows)\n",
    "\n",
    "        owner_query_df = pd.concat([owner_query_df, temp_df], ignore_index=True)\n",
    "        owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{yearOfQuery}.txt', sep='\\t', index=False)\n",
    "    \n",
    "  else:\n",
    "\n",
    "\n",
    "     for idx, file in enumerate(os.listdir(data_directory)):\n",
    "      owner_query_df = pd.DataFrame()\n",
    "      if f\"transArchive_{yearOfQuery}\" in file:\n",
    "      \n",
    "\n",
    "        owner_gbq_query = f\"\"\"\n",
    "        SELECT\n",
    "          *,\n",
    "        SAFE_CAST(Scale AS INT64) AS IntScale\n",
    "        FROM\n",
    "          `the_wedge_dataset.{file.split('.')[0]}`\n",
    "        WHERE card_no = 48289.0 OR card_no = 48420.0 OR card_no = 56191.0 OR card_no = 20300.0 OR card_no = 48996.0 OR card_no = 56191.0 OR card_no = 16551.0 \n",
    "        \"\"\"\n",
    "\n",
    "        temp_df = run_query2(owner_gbq_query)\n",
    "\n",
    "        # #temp_df = pl.DataFrame(results)\n",
    "\n",
    "        # rows = [dict(row) for row in results]\n",
    "        # #columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "        # # Create Polars DataFrame from the rows\n",
    "        # temp_df = pl.DataFrame(rows)\n",
    "\n",
    "        owner_query_df = pd.concat([owner_query_df, temp_df], ignore_index=True)\n",
    "        owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{file.split('.')[0]}_version2.txt', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# if results is None or len(results) == 0:\n",
    "#     print(\"No results found or query returned None.\")\n",
    "# else:\n",
    "#     # Process the rows if results exist\n",
    "#     rows = [dict(row) for row in results]\n",
    "#     columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "#     # Create Polars DataFrame from the rows\n",
    "#     gbq_query_df = pl.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'os' is not defined with year 2010\n",
      "Error: name 'os' is not defined with year 2011\n",
      "Error: name 'os' is not defined with year 2012\n",
      "Error: name 'os' is not defined with year 2013\n",
      "Error: name 'os' is not defined with year 2014\n",
      "Error: name 'os' is not defined with year 2015\n",
      "Error: name 'os' is not defined with year 2016\n",
      "Error: name 'os' is not defined with year 2017\n"
     ]
    }
   ],
   "source": [
    "for x in range(2010, 2018):\n",
    "    try:\n",
    "        save_owner_query_to_file(x, tableByTable=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with year {x}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Queries for 2015 and 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\666650559.py:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{fileNameForQuery}.txt', sep='\\t', index=False)\n",
      "c:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed: 322.89 MB\n",
      "Estimated bytes processed: 338571368\n",
      "Estimated cost: $0.0015396443\n",
      "\n",
      "\n",
      "Estimated bytes processed against a full year of data: 16928568400\n",
      "Estimated cost against a full year of data: $0.07698221634200308472\n",
      "Estimated cost against a full year of data every 6 hours: $112.39403585932450369000\n",
      "\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "owner_query_df = pd.DataFrame()\n",
    "\n",
    "fileNameForQuery = \"transArchive_201510\"\n",
    "\n",
    "owner_gbq_query = f\"\"\"\n",
    "        SELECT\n",
    "          *\n",
    "        FROM\n",
    "          `the_wedge_dataset.{fileNameForQuery}*`\n",
    "        WHERE card_no = 48289.0 OR card_no = 48420.0 OR card_no = 56191.0 OR card_no = 20300.0 OR card_no = 48996.0 OR card_no = 56191.0 OR card_no = 16551.0 \n",
    "        \"\"\"\n",
    "\n",
    "temp_df = run_query2(owner_gbq_query)\n",
    "\n",
    "# #temp_df = pl.DataFrame(results)\n",
    "\n",
    "# rows = [dict(row) for row in results]\n",
    "# #columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "# # Create Polars DataFrame from the rows\n",
    "# temp_df = pl.DataFrame(rows)\n",
    "\n",
    "owner_query_df = pd.concat([owner_query_df, temp_df], ignore_index=True)\n",
    "owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{fileNameForQuery}.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containing the Data into a Single Dataframe and File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<string>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:8: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  for idx, file in enumerate(os.listdir('E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder')):\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\{file}', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:11: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\{file}', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_owner_df = pd.concat([final_owner_df, temp_df], axis=0)\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_owner_df = pd.concat([final_owner_df, temp_df], axis=0)\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_owner_df = pd.concat([final_owner_df, temp_df], axis=0)\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_owner_df = pd.concat([final_owner_df, temp_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 13] Permission denied: 'E:\\\\College\\\\Fall 2024\\\\ADA\\\\Wedge\\\\Wedge_Project\\\\owner_data_folder\\\\graveyard' with file graveyard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\2019297716.py:11: DtypeWarning: Columns (33,34,40,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\{file}', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "columns = ['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id', 'IntScale']\n",
    "\n",
    "# Create an empty Polars DataFrame with the specified columns\n",
    "final_owner_df = pd.DataFrame({col: [] for col in columns})\n",
    "\n",
    "\n",
    "\n",
    "for idx, file in enumerate(os.listdir('E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder')):\n",
    "\n",
    "    try:\n",
    "        temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\{file}', sep='\\t')\n",
    "        \n",
    "        final_owner_df = pd.concat([final_owner_df, temp_df], axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with file {file}\")\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_owner_df.drop('IntScale', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_2364\\3082844610.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  final_owner_df.to_csv('E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data_2.txt', sep='\\t', index=False)\n"
     ]
    }
   ],
   "source": [
    "final_owner_df.to_csv('E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data_2.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_11028\\380248305.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_11028\\380248305.py:1: DtypeWarning: Columns (33,34,40,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
