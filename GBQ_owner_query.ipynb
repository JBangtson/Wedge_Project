{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wedge Project - Task Two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import GoogleAPIError\n",
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "client = bigquery.Client(project=\"wedge-project-jbangtson\")\n",
    "data_directory = \"E:\\\\College\\\\Fall 2024\\\\ADA\\\\Wedge\\\\Wedge_Project\\\\data\\\\unzipped\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_19420\\380248305.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_19420\\380248305.py:1: DtypeWarning: Columns (33,34,40,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above to view all transactions for card owners: \n",
    "\n",
    "48289, 48420, 56191, 20300, 48996, 56191, and 16551.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 50)\n",
      "┌──────────┬─────────────┬────────┬──────────┬───┬───────┬────────┬──────────┬──────────┐\n",
      "│ datetime ┆ register_no ┆ emp_no ┆ trans_no ┆ … ┆ store ┆ branch ┆ match_id ┆ trans_id │\n",
      "│ ---      ┆ ---         ┆ ---    ┆ ---      ┆   ┆ ---   ┆ ---    ┆ ---      ┆ ---      │\n",
      "│ null     ┆ null        ┆ null   ┆ null     ┆   ┆ null  ┆ null   ┆ null     ┆ null     │\n",
      "╞══════════╪═════════════╪════════╪══════════╪═══╪═══════╪════════╪══════════╪══════════╡\n",
      "└──────────┴─────────────┴────────┴──────────┴───┴───────┴────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# List of columns\n",
    "columns = ['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id']\n",
    "\n",
    "# Create an empty Polars DataFrame with the specified columns\n",
    "gbq_query_df = pl.DataFrame({col: [] for col in columns})\n",
    "\n",
    "print(gbq_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a query\n",
    "def run_query(query):\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "\n",
    "        bytes_processed = query_job.total_bytes_processed\n",
    "        mb_processed = bytes_processed / (1024 ** 2)\n",
    "        cost_per_tb = 5.0\n",
    "\n",
    "\n",
    "        tb_processed = bytes_processed / (1024 ** 4)  # Convert bytes to terabytes\n",
    "        estimated_cost = tb_processed * cost_per_tb\n",
    "\n",
    "        # Display the processed data and estimated cost\n",
    "        print(f\"Data processed: {mb_processed:.2f} MB\")\n",
    "        \n",
    "\n",
    "        print(f\"Estimated bytes processed: {bytes_processed}\")\n",
    "        print(f\"Estimated cost: ${estimated_cost:.10f}\\n\\n\")\n",
    "\n",
    "        print(f\"Estimated bytes processed against a full year of data: {bytes_processed*50}\")\n",
    "        print(f\"Estimated cost against a full year of data: ${estimated_cost*50:.20f}\")\n",
    "        print(f\"Estimated cost against a full year of data every 6 hours: ${(estimated_cost*50)*(4*365):.20f}\\n\\n---------------\")\n",
    "\n",
    "        \n",
    "\n",
    "        return results\n",
    "    except GoogleAPIError as e:\n",
    "        print(f\"Error running query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This next function is a modified version of the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a query\n",
    "def run_query2(query):\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        df = query_job.to_dataframe()\n",
    "        #results = query_job.result()\n",
    "\n",
    "        bytes_processed = query_job.total_bytes_processed\n",
    "        mb_processed = bytes_processed / (1024 ** 2)\n",
    "        cost_per_tb = 5.0\n",
    "\n",
    "\n",
    "        tb_processed = bytes_processed / (1024 ** 4)  # Convert bytes to terabytes\n",
    "        estimated_cost = tb_processed * cost_per_tb\n",
    "\n",
    "        # Display the processed data and estimated cost\n",
    "        print(f\"Data processed: {mb_processed:.2f} MB\")\n",
    "        \n",
    "\n",
    "        print(f\"Estimated bytes processed: {bytes_processed}\")\n",
    "        print(f\"Estimated cost: ${estimated_cost:.10f}\\n\\n\")\n",
    "\n",
    "        print(f\"Estimated bytes processed against a full year of data: {bytes_processed*50}\")\n",
    "        print(f\"Estimated cost against a full year of data: ${estimated_cost*50:.20f}\")\n",
    "        print(f\"Estimated cost against a full year of data every 6 hours: ${(estimated_cost*50)*(4*365):.20f}\\n\\n---------------\")\n",
    "\n",
    "        \n",
    "\n",
    "        return df.astype(str)\n",
    "    except GoogleAPIError as e:\n",
    "        print(f\"Error running query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed: 654.30 MB\n",
      "Estimated bytes processed: 686080992\n",
      "Estimated cost: $0.0031199351\n",
      "\n",
      "\n",
      "Estimated bytes processed against a full year of data: 34304049600\n",
      "Estimated cost against a full year of data: $0.15599675680277869105\n",
      "Estimated cost against a full year of data every 6 hours: $227.75526493205688893795\n",
      "\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "all_card_nums = []\n",
    "\n",
    "distinct_card_nums = \"\"\"\n",
    "SELECT distinct(card_no)\n",
    "FROM `the_wedge_dataset.transArchive_*`\n",
    "WHERE card_no != 3;\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and display results\n",
    "results = run_query2(distinct_card_nums)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select 20 random numbers from the all_card_nums list\n",
    "\n",
    "# results = list(results['card_no'])\n",
    "# random_card_nums = random.sample(results, 100)\n",
    "# print(random_card_nums)\n",
    "\n",
    "# Write the random_card_nums list to a tab-delimited text file\n",
    "# with open('random_card_nums.txt', 'w') as f:\n",
    "#     for num in random_card_nums:\n",
    "#         f.write(f\"{num}\\t\")\n",
    "\n",
    "# Read the random_card_nums file into a list\n",
    "with open('random_card_nums.txt', 'r') as f:\n",
    "    random_card_nums = f.read().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_card_nums.txt', 'r') as f:\n",
    "    random_card_nums_string = f.read()\n",
    "\n",
    "\n",
    "random_card_nums_string = random_card_nums_string.replace(\"\\t\", \", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBQ Owner Queries\n",
    "\n",
    "This code defines a function save_owner_query_to_file() that retrieves and saves data from a Google BigQuery dataset to a CSV file. \n",
    "\n",
    "The function takes two arguments: yearOfQuery (the year to filter the data by) and table-by-table \n",
    "(a boolean flag that controls whether to process each table individually or as a group). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_19420\\2109633670.py:30: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{yearOfQuery}.txt', sep='\\t', index=False)\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_19420\\2109633670.py:60: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{file.split('.')[0]}_version2.txt', sep='\\t', index=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def save_owner_query_to_file(yearOfQuery, tableByTable=False):\n",
    "    \n",
    "  if tableByTable:\n",
    "\n",
    "    for idx, file in enumerate(os.listdir(data_directory)):\n",
    "      owner_query_df = pd.DataFrame()\n",
    "      if f\"transArchive_{yearOfQuery}\" in file:\n",
    "      \n",
    "\n",
    "        owner_gbq_query = f\"\"\"\n",
    "        SELECT\n",
    "          *,\n",
    "        SAFE_CAST(Scale AS INT64) AS IntScale\n",
    "        FROM\n",
    "          `the_wedge_dataset.transArchive_{yearOfQuery}*`\n",
    "        WHERE card_no in ({random_card_nums_string}) \n",
    "        \"\"\"\n",
    "\n",
    "        temp_df = run_query2(owner_gbq_query)\n",
    "\n",
    "        # #temp_df = pl.DataFrame(results)\n",
    "\n",
    "        # rows = [dict(row) for row in results]\n",
    "        # #columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "        # # Create Polars DataFrame from the rows\n",
    "        # temp_df = pl.DataFrame(rows)\n",
    "\n",
    "        owner_query_df = pd.concat([owner_query_df, temp_df], ignore_index=True)\n",
    "        owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{yearOfQuery}.txt', sep='\\t', index=False)\n",
    "    \n",
    "  else:\n",
    "\n",
    "\n",
    "     for idx, file in enumerate(os.listdir(data_directory)):\n",
    "      owner_query_df = pd.DataFrame()\n",
    "      if f\"transArchive_{yearOfQuery}\" in file:\n",
    "      \n",
    "\n",
    "        owner_gbq_query = f\"\"\"\n",
    "        SELECT\n",
    "          *,\n",
    "        SAFE_CAST(Scale AS INT64) AS IntScale\n",
    "        FROM\n",
    "          `the_wedge_dataset.{file.split('.')[0]}`\n",
    "        WHERE card_no in ({random_card_nums_string}) \n",
    "        \"\"\"\n",
    "\n",
    "        temp_df = run_query2(owner_gbq_query)\n",
    "\n",
    "        # #temp_df = pl.DataFrame(results)\n",
    "\n",
    "        # rows = [dict(row) for row in results]\n",
    "        # #columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "        # # Create Polars DataFrame from the rows\n",
    "        # temp_df = pl.DataFrame(rows)\n",
    "\n",
    "        owner_query_df = pd.concat([owner_query_df, temp_df], ignore_index=True)\n",
    "        owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\owner_data_{file.split('.')[0]}_version2.txt', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# if results is None or len(results) == 0:\n",
    "#     print(\"No results found or query returned None.\")\n",
    "# else:\n",
    "#     # Process the rows if results exist\n",
    "#     rows = [dict(row) for row in results]\n",
    "#     columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "#     # Create Polars DataFrame from the rows\n",
    "#     gbq_query_df = pl.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'random_card_nums_string' is not defined with year 2010\n",
      "Error: name 'random_card_nums_string' is not defined with year 2011\n",
      "Error: name 'random_card_nums_string' is not defined with year 2012\n",
      "Error: name 'random_card_nums_string' is not defined with year 2013\n",
      "Error: name 'random_card_nums_string' is not defined with year 2014\n",
      "Error: name 'random_card_nums_string' is not defined with year 2015\n",
      "Error: name 'random_card_nums_string' is not defined with year 2016\n",
      "Error: name 'random_card_nums_string' is not defined with year 2017\n"
     ]
    }
   ],
   "source": [
    "for x in range(2010, 2018):\n",
    "    try:\n",
    "        save_owner_query_to_file(x, tableByTable=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with year {x}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Queries for 2015 and 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_19420\\2822336455.py:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\owner_data_{fileNameForQuery}.txt', sep='\\t', index=False)\n",
      "c:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed: 29211.74 MB\n",
      "Estimated bytes processed: 30630727708\n",
      "Estimated cost: $0.1392924228\n",
      "\n",
      "\n",
      "Estimated bytes processed against a full year of data: 1531536385400\n",
      "Estimated cost against a full year of data: $6.96462114046880742535\n",
      "Estimated cost against a full year of data every 6 hours: $10168.34686508445884101093\n",
      "\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "owner_query_df = pd.DataFrame()\n",
    "random_card_nums_string = random_card_nums_string[:-2]\n",
    "fileNameForQuery = \"transArchive_\"\n",
    "\n",
    "owner_gbq_query = f\"\"\"\n",
    "        SELECT\n",
    "          *\n",
    "        FROM\n",
    "          `the_wedge_dataset.transArchive_*`\n",
    "        WHERE card_no in ({random_card_nums_string});\n",
    "        \"\"\"\n",
    "\n",
    "temp_df = run_query2(owner_gbq_query)\n",
    "\n",
    "# #temp_df = pl.DataFrame(results)\n",
    "\n",
    "# rows = [dict(row) for row in results]\n",
    "# #columns = list(rows[0].keys()) if rows else []\n",
    "\n",
    "# # Create Polars DataFrame from the rows\n",
    "# temp_df = pl.DataFrame(rows)\n",
    "\n",
    "owner_query_df = pd.concat([owner_query_df, temp_df], ignore_index=True)\n",
    "owner_query_df.to_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\owner_data_{fileNameForQuery}.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comma from last card number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containing the Data into a Single Dataframe and File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<string>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_6232\\1814281473.py:11: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\{file}', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_6232\\1814281473.py:11: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\{file}', sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No columns to parse from file with file owner_data_transArchive_2014.txt\n",
      "Error: No columns to parse from file with file owner_data_transArchive_20151.txt\n",
      "Error: No columns to parse from file with file owner_data_transArchive_2016.txt\n"
     ]
    }
   ],
   "source": [
    "columns = ['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id', 'IntScale']\n",
    "\n",
    "# Create an empty Polars DataFrame with the specified columns\n",
    "final_owner_df = pd.DataFrame({col: [] for col in columns})\n",
    "\n",
    "\n",
    "\n",
    "for idx, file in enumerate(os.listdir('owner_data_folder_redo')):\n",
    "    \n",
    "    try:\n",
    "        temp_df = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\{file}', sep='\\t')\n",
    "        \n",
    "        final_owner_df = pd.concat([final_owner_df, temp_df], axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with file {file}\")\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_owner_df.drop('IntScale', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_6232\\1035160173.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  final_owner_df.to_csv('E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\_final_owner_data.txt', sep='\\t', index=False)\n"
     ]
    }
   ],
   "source": [
    "final_owner_df.to_csv('E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder_redo\\_final_owner_data.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_11028\\380248305.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n",
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_11028\\380248305.py:1: DtypeWarning: Columns (33,34,40,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wedge_task_two = pd.read_csv(f'E:\\College\\Fall 2024\\ADA\\Wedge\\Wedge_Project\\owner_data_folder\\_final_owner_data.txt', sep='\\t')\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
